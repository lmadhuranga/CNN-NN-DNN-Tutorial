{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcCuQg_sLtSf"
   },
   "source": [
    "# CNN Training with Fashion Data set - Pytorch A - Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5hx5mp8WFcVn",
    "outputId": "c2d4849b-dd27-4840-ddb6-2b21f95f8f3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1be5e4d7988>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tranforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)  # Displa optin for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nk-eQZlLHbDb",
    "outputId": "46b79b48-9d53-4b70-bf86-194a37efb48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KJPGY6-HbAH"
   },
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0VgoSijMHTf"
   },
   "source": [
    "## Load data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9XoXxunMGrV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                     | 0/26421880 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|                                                                      | 16384/26421880 [00:00<05:31, 79599.36it/s]\n",
      "\n",
      "  0%|▏                                                                     | 49152/26421880 [00:00<04:31, 97105.34it/s]\n",
      "\n",
      "  0%|▎                                                                   | 106496/26421880 [00:01<03:30, 124904.74it/s]\n",
      "\n",
      "  1%|▌                                                                   | 221184/26421880 [00:01<02:36, 167828.80it/s]\n",
      "\n",
      "  1%|▊                                                                   | 294912/26421880 [00:01<02:01, 215831.41it/s]\n",
      "\n",
      "  1%|▉                                                                   | 385024/26421880 [00:01<01:33, 279041.49it/s]\n",
      "\n",
      "  2%|█▎                                                                  | 499712/26421880 [00:01<01:11, 360066.96it/s]\n",
      "\n",
      "  2%|█▋                                                                  | 638976/26421880 [00:01<00:55, 461935.86it/s]\n",
      "\n",
      "  3%|██                                                                  | 786432/26421880 [00:01<00:45, 567482.56it/s]\n",
      "\n",
      "  4%|██▍                                                                 | 942080/26421880 [00:01<00:36, 690273.82it/s]\n",
      "\n",
      "  4%|██▋                                                                | 1073152/26421880 [00:02<00:31, 803188.02it/s]\n",
      "\n",
      "  5%|███                                                                | 1220608/26421880 [00:02<00:27, 929922.41it/s]\n",
      "\n",
      "  5%|███▍                                                              | 1351680/26421880 [00:02<00:24, 1008732.33it/s]\n",
      "\n",
      "  6%|███▋                                                              | 1482752/26421880 [00:02<00:23, 1049689.97it/s]\n",
      "\n",
      "  6%|████                                                              | 1630208/26421880 [00:02<00:21, 1137103.69it/s]\n",
      "\n",
      "  7%|████▍                                                             | 1769472/26421880 [00:02<00:20, 1200722.89it/s]\n",
      "\n",
      "  7%|████▊                                                             | 1908736/26421880 [00:02<00:19, 1239201.06it/s]\n",
      "\n",
      "  8%|█████▏                                                            | 2056192/26421880 [00:02<00:18, 1285367.62it/s]\n",
      "\n",
      "  8%|█████▍                                                            | 2195456/26421880 [00:02<00:19, 1231087.64it/s]\n",
      "\n",
      "  9%|█████▊                                                            | 2342912/26421880 [00:02<00:18, 1281536.40it/s]\n",
      "\n",
      " 10%|██████▎                                                           | 2539520/26421880 [00:03<00:16, 1429445.81it/s]\n",
      "\n",
      " 10%|██████▋                                                           | 2695168/26421880 [00:03<00:16, 1449055.91it/s]\n",
      "\n",
      " 11%|███████                                                           | 2850816/26421880 [00:03<00:16, 1471445.22it/s]\n",
      "\n",
      " 11%|███████▌                                                          | 3006464/26421880 [00:03<00:15, 1479260.41it/s]\n",
      "\n",
      " 12%|███████▉                                                          | 3162112/26421880 [00:03<00:15, 1500918.19it/s]\n",
      "\n",
      " 13%|████████▎                                                         | 3317760/26421880 [00:03<00:15, 1472854.10it/s]\n",
      "\n",
      " 13%|████████▋                                                         | 3473408/26421880 [00:03<00:18, 1271665.94it/s]\n",
      "\n",
      " 14%|█████████▏                                                        | 3661824/26421880 [00:03<00:16, 1405434.61it/s]\n",
      "\n",
      " 14%|█████████▌                                                        | 3817472/26421880 [00:03<00:16, 1393009.80it/s]\n",
      "\n",
      " 15%|█████████▉                                                        | 3981312/26421880 [00:04<00:15, 1423753.12it/s]\n",
      "\n",
      " 16%|██████████▎                                                       | 4153344/26421880 [00:04<00:14, 1491155.10it/s]\n",
      "\n",
      " 16%|██████████▊                                                       | 4308992/26421880 [00:04<00:15, 1455796.32it/s]\n",
      "\n",
      " 17%|███████████▏                                                      | 4464640/26421880 [00:04<00:15, 1387954.06it/s]\n",
      "\n",
      " 17%|███████████▌                                                      | 4612096/26421880 [00:04<00:21, 1014672.90it/s]\n",
      "\n",
      " 18%|████████████                                                       | 4734976/26421880 [00:04<00:25, 843048.66it/s]\n",
      "\n",
      " 19%|████████████▍                                                      | 4890624/26421880 [00:04<00:22, 975114.37it/s]\n",
      "\n",
      " 19%|████████████▋                                                     | 5054464/26421880 [00:05<00:19, 1100632.98it/s]\n",
      "\n",
      " 20%|█████████████                                                     | 5226496/26421880 [00:05<00:17, 1219861.69it/s]\n",
      "\n",
      " 20%|█████████████▍                                                    | 5382144/26421880 [00:05<00:16, 1294006.54it/s]\n",
      "\n",
      " 21%|█████████████▊                                                    | 5529600/26421880 [00:05<00:15, 1341215.52it/s]\n",
      "\n",
      " 21%|██████████████▏                                                   | 5677056/26421880 [00:05<00:19, 1082746.66it/s]\n",
      "\n",
      " 22%|██████████████▌                                                   | 5832704/26421880 [00:05<00:17, 1190812.33it/s]\n",
      "\n",
      " 23%|██████████████▉                                                   | 6004736/26421880 [00:05<00:15, 1302584.65it/s]\n",
      "\n",
      " 23%|███████████████▍                                                  | 6168576/26421880 [00:05<00:15, 1328227.46it/s]\n",
      "\n",
      " 24%|███████████████▊                                                  | 6316032/26421880 [00:06<00:16, 1216056.99it/s]\n",
      "\n",
      " 24%|████████████████                                                  | 6455296/26421880 [00:06<00:15, 1254410.16it/s]\n",
      "\n",
      " 25%|████████████████▌                                                 | 6610944/26421880 [00:06<00:14, 1324355.89it/s]\n",
      "\n",
      " 26%|████████████████▊                                                 | 6750208/26421880 [00:06<00:14, 1321581.22it/s]\n",
      "\n",
      " 26%|█████████████████▎                                                | 6905856/26421880 [00:06<00:14, 1377066.33it/s]\n",
      "\n",
      " 27%|█████████████████▌                                                | 7053312/26421880 [00:06<00:17, 1137152.30it/s]\n",
      "\n",
      " 27%|█████████████████▉                                                | 7176192/26421880 [00:06<00:17, 1101209.44it/s]\n",
      "\n",
      " 28%|██████████████████▎                                               | 7307264/26421880 [00:06<00:16, 1139479.84it/s]\n",
      "\n",
      " 28%|██████████████████▌                                               | 7454720/26421880 [00:06<00:15, 1206314.56it/s]\n",
      "\n",
      " 29%|███████████████████                                               | 7626752/26421880 [00:07<00:14, 1280423.02it/s]\n",
      "\n",
      " 29%|███████████████████▍                                              | 7766016/26421880 [00:07<00:15, 1206306.83it/s]\n",
      "\n",
      " 30%|███████████████████▋                                              | 7897088/26421880 [00:07<00:16, 1132578.97it/s]\n",
      "\n",
      " 30%|████████████████████                                              | 8052736/26421880 [00:07<00:15, 1209640.33it/s]\n",
      "\n",
      " 31%|████████████████████▍                                             | 8183808/26421880 [00:07<00:14, 1234388.53it/s]\n",
      "\n",
      " 31%|█████████████████████                                              | 8314880/26421880 [00:07<00:19, 947729.78it/s]\n",
      "\n",
      " 32%|█████████████████████▍                                             | 8429568/26421880 [00:07<00:18, 960407.74it/s]\n",
      "\n",
      " 32%|█████████████████████▍                                            | 8560640/26421880 [00:08<00:17, 1006561.46it/s]\n",
      "\n",
      " 33%|█████████████████████▋                                            | 8699904/26421880 [00:08<00:16, 1095288.77it/s]\n",
      "\n",
      " 33%|██████████████████████                                            | 8830976/26421880 [00:08<00:15, 1149609.27it/s]\n",
      "\n",
      " 34%|██████████████████████▋                                            | 8953856/26421880 [00:08<00:17, 992979.34it/s]\n",
      "\n",
      " 34%|██████████████████████▉                                            | 9068544/26421880 [00:08<00:20, 837460.87it/s]\n",
      "\n",
      " 35%|███████████████████████▎                                           | 9183232/26421880 [00:08<00:19, 904688.28it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████▌                                           | 9289728/26421880 [00:08<00:18, 903920.10it/s]\n",
      "\n",
      " 36%|███████████████████████▊                                           | 9396224/26421880 [00:08<00:18, 931323.50it/s]\n",
      "\n",
      " 36%|████████████████████████                                           | 9494528/26421880 [00:09<00:18, 893867.92it/s]\n",
      "\n",
      " 36%|████████████████████████▎                                          | 9601024/26421880 [00:09<00:18, 931513.08it/s]\n",
      "\n",
      " 37%|████████████████████████▌                                          | 9699328/26421880 [00:09<00:19, 848569.10it/s]\n",
      "\n",
      " 37%|████████████████████████▊                                          | 9805824/26421880 [00:09<00:18, 884226.91it/s]\n",
      "\n",
      " 38%|█████████████████████████▏                                         | 9920512/26421880 [00:09<00:17, 940629.56it/s]\n",
      "\n",
      " 38%|█████████████████████████                                         | 10027008/26421880 [00:09<00:17, 960641.56it/s]\n",
      "\n",
      " 39%|█████████████████████████                                        | 10174464/26421880 [00:09<00:15, 1038195.72it/s]\n",
      "\n",
      " 39%|█████████████████████████▎                                       | 10313728/26421880 [00:09<00:14, 1118148.86it/s]\n",
      "\n",
      " 39%|█████████████████████████▋                                       | 10436608/26421880 [00:09<00:14, 1098927.56it/s]\n",
      "\n",
      " 40%|█████████████████████████▉                                       | 10551296/26421880 [00:10<00:14, 1108737.16it/s]\n",
      "\n",
      " 41%|██████████████████████████▎                                      | 10715136/26421880 [00:10<00:12, 1223609.37it/s]\n",
      "\n",
      " 41%|██████████████████████████▋                                      | 10846208/26421880 [00:10<00:14, 1056449.47it/s]\n",
      "\n",
      " 42%|███████████████████████████                                      | 10977280/26421880 [00:10<00:14, 1094515.55it/s]\n",
      "\n",
      " 42%|███████████████████████████▎                                     | 11116544/26421880 [00:10<00:13, 1141341.60it/s]\n",
      "\n",
      " 43%|███████████████████████████▋                                     | 11239424/26421880 [00:10<00:14, 1014744.42it/s]\n",
      "\n",
      " 43%|███████████████████████████▉                                     | 11354112/26421880 [00:10<00:14, 1019181.16it/s]\n",
      "\n",
      " 43%|████████████████████████████▏                                    | 11476992/26421880 [00:10<00:14, 1065539.91it/s]\n",
      "\n",
      " 44%|████████████████████████████▉                                     | 11591680/26421880 [00:11<00:19, 776922.91it/s]\n",
      "\n",
      " 45%|█████████████████████████████▋                                    | 11878400/26421880 [00:11<00:14, 991801.84it/s]\n",
      "\n",
      " 46%|█████████████████████████████▌                                   | 12034048/26421880 [00:11<00:13, 1029957.42it/s]\n",
      "\n",
      " 46%|█████████████████████████████▉                                   | 12173312/26421880 [00:11<00:13, 1046935.00it/s]\n",
      "\n",
      " 47%|██████████████████████████████▍                                  | 12361728/26421880 [00:11<00:11, 1194409.26it/s]\n",
      "\n",
      " 47%|██████████████████████████████▊                                  | 12509184/26421880 [00:11<00:12, 1104797.64it/s]\n",
      "\n",
      " 48%|███████████████████████████████▏                                 | 12681216/26421880 [00:11<00:11, 1233943.76it/s]\n",
      "\n",
      " 49%|███████████████████████████████▌                                 | 12828672/26421880 [00:11<00:10, 1295478.04it/s]\n",
      "\n",
      " 49%|███████████████████████████████▉                                 | 12992512/26421880 [00:12<00:10, 1315941.06it/s]\n",
      "\n",
      " 50%|████████████████████████████████▍                                | 13189120/26421880 [00:12<00:09, 1453521.41it/s]\n",
      "\n",
      " 51%|████████████████████████████████▊                                | 13361152/26421880 [00:12<00:08, 1478565.75it/s]\n",
      "\n",
      " 51%|█████████████████████████████████▎                               | 13516800/26421880 [00:12<00:09, 1416117.78it/s]\n",
      "\n",
      " 52%|█████████████████████████████████▋                               | 13672448/26421880 [00:12<00:10, 1272562.46it/s]\n",
      "\n",
      " 52%|█████████████████████████████████▉                               | 13811712/26421880 [00:12<00:11, 1126583.43it/s]\n",
      "\n",
      " 53%|██████████████████████████████████▍                              | 13983744/26421880 [00:12<00:10, 1242043.70it/s]\n",
      "\n",
      " 54%|██████████████████████████████████▊                              | 14139392/26421880 [00:12<00:09, 1320365.73it/s]\n",
      "\n",
      " 54%|███████████████████████████████████▏                             | 14311424/26421880 [00:12<00:08, 1408277.65it/s]\n",
      "\n",
      " 55%|███████████████████████████████████▌                             | 14467072/26421880 [00:13<00:08, 1420003.39it/s]\n",
      "\n",
      " 55%|███████████████████████████████████▉                             | 14622720/26421880 [00:13<00:08, 1455880.80it/s]\n",
      "\n",
      " 56%|████████████████████████████████████▎                            | 14778368/26421880 [00:13<00:07, 1481233.59it/s]\n",
      "\n",
      " 57%|████████████████████████████████████▋                            | 14934016/26421880 [00:13<00:07, 1474612.34it/s]\n",
      "\n",
      " 57%|█████████████████████████████████████                            | 15089664/26421880 [00:13<00:09, 1150323.15it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████                            | 15220736/26421880 [00:13<00:11, 979523.05it/s]\n",
      "\n",
      " 58%|█████████████████████████████████████▊                           | 15368192/26421880 [00:13<00:10, 1078568.29it/s]\n",
      "\n",
      " 59%|██████████████████████████████████████▏                          | 15515648/26421880 [00:14<00:09, 1161882.23it/s]\n",
      "\n",
      " 59%|██████████████████████████████████████▍                          | 15646720/26421880 [00:14<00:10, 1007630.50it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████▎                          | 15761408/26421880 [00:14<00:11, 920905.60it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████▋                          | 15867904/26421880 [00:14<00:13, 802371.61it/s]\n",
      "\n",
      " 60%|███████████████████████████████████████▊                          | 15958016/26421880 [00:14<00:15, 654259.94it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████                          | 16039936/26421880 [00:14<00:16, 632460.30it/s]\n",
      "\n",
      " 61%|████████████████████████████████████████▍                         | 16171008/26421880 [00:14<00:13, 741637.45it/s]\n",
      "\n",
      " 62%|████████████████████████████████████████▋                         | 16285696/26421880 [00:15<00:12, 824317.92it/s]\n",
      "\n",
      " 62%|████████████████████████████████████████▉                         | 16392192/26421880 [00:15<00:11, 838245.08it/s]\n",
      "\n",
      " 63%|█████████████████████████████████████████▎                        | 16556032/26421880 [00:15<00:10, 973945.84it/s]\n",
      "\n",
      " 63%|█████████████████████████████████████████▏                       | 16736256/26421880 [00:15<00:08, 1124902.74it/s]\n",
      "\n",
      " 64%|█████████████████████████████████████████▌                       | 16908288/26421880 [00:15<00:07, 1245811.22it/s]\n",
      "\n",
      " 65%|█████████████████████████████████████████▉                       | 17055744/26421880 [00:15<00:07, 1291806.15it/s]\n",
      "\n",
      " 65%|██████████████████████████████████████████▎                      | 17203200/26421880 [00:15<00:08, 1052555.28it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████▎                      | 17326080/26421880 [00:15<00:09, 936249.43it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████▌                      | 17440768/26421880 [00:16<00:09, 974407.79it/s]\n",
      "\n",
      " 67%|███████████████████████████████████████████▏                     | 17571840/26421880 [00:16<00:08, 1042623.26it/s]\n",
      "\n",
      " 67%|███████████████████████████████████████████▌                     | 17702912/26421880 [00:16<00:07, 1104958.95it/s]\n",
      "\n",
      " 67%|███████████████████████████████████████████▊                     | 17833984/26421880 [00:16<00:07, 1157159.37it/s]\n",
      "\n",
      " 68%|████████████████████████████████████████████▏                    | 17956864/26421880 [00:16<00:07, 1158080.32it/s]\n",
      "\n",
      " 68%|████████████████████████████████████████████▍                    | 18079744/26421880 [00:16<00:07, 1161764.55it/s]\n",
      "\n",
      " 69%|████████████████████████████████████████████▊                    | 18202624/26421880 [00:16<00:07, 1147033.98it/s]\n",
      "\n",
      " 69%|█████████████████████████████████████████████                    | 18325504/26421880 [00:16<00:07, 1154857.39it/s]\n",
      "\n",
      " 70%|█████████████████████████████████████████████▍                   | 18456576/26421880 [00:16<00:06, 1185116.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████▋                   | 18579456/26421880 [00:16<00:06, 1174261.63it/s]\n",
      "\n",
      " 71%|██████████████████████████████████████████████                   | 18702336/26421880 [00:17<00:06, 1182679.03it/s]\n",
      "\n",
      " 71%|██████████████████████████████████████████████▎                  | 18841600/26421880 [00:17<00:06, 1186641.84it/s]\n",
      "\n",
      " 72%|███████████████████████████████████████████████▎                  | 18964480/26421880 [00:17<00:07, 942871.05it/s]\n",
      "\n",
      " 73%|███████████████████████████████████████████████▎                 | 19218432/26421880 [00:17<00:06, 1157904.29it/s]\n",
      "\n",
      " 73%|███████████████████████████████████████████████▋                 | 19365888/26421880 [00:17<00:06, 1164236.25it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████▉                 | 19505152/26421880 [00:17<00:05, 1201334.45it/s]\n",
      "\n",
      " 74%|████████████████████████████████████████████████▎                | 19644416/26421880 [00:17<00:05, 1236992.60it/s]\n",
      "\n",
      " 75%|████████████████████████████████████████████████▋                | 19808256/26421880 [00:17<00:05, 1319790.90it/s]\n",
      "\n",
      " 76%|█████████████████████████████████████████████████▏               | 19988480/26421880 [00:18<00:04, 1434268.62it/s]\n",
      "\n",
      " 76%|█████████████████████████████████████████████████▌               | 20144128/26421880 [00:18<00:04, 1424606.14it/s]\n",
      "\n",
      " 77%|██████████████████████████████████████████████████               | 20332544/26421880 [00:18<00:04, 1519660.08it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████▍              | 20496384/26421880 [00:18<00:03, 1517489.51it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████▊              | 20660224/26421880 [00:18<00:03, 1536530.25it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████▏             | 20824064/26421880 [00:18<00:03, 1418619.18it/s]\n",
      "\n",
      " 79%|███████████████████████████████████████████████████▌             | 20971520/26421880 [00:18<00:04, 1320243.57it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████▉             | 21110784/26421880 [00:18<00:04, 1246673.28it/s]\n",
      "\n",
      " 80%|████████████████████████████████████████████████████▎            | 21241856/26421880 [00:19<00:04, 1175806.46it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████▌            | 21372928/26421880 [00:19<00:04, 1198897.43it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████▉            | 21504000/26421880 [00:19<00:04, 1227321.40it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████▏           | 21635072/26421880 [00:19<00:03, 1218819.18it/s]\n",
      "\n",
      " 82%|█████████████████████████████████████████████████████▌           | 21774336/26421880 [00:19<00:03, 1241491.87it/s]\n",
      "\n",
      " 83%|█████████████████████████████████████████████████████▉           | 21913600/26421880 [00:19<00:03, 1278772.53it/s]\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████▎          | 22061056/26421880 [00:19<00:03, 1297046.55it/s]\n",
      "\n",
      " 84%|██████████████████████████████████████████████████████▋          | 22216704/26421880 [00:19<00:03, 1362485.14it/s]\n",
      "\n",
      " 85%|██████████████████████████████████████████████████████▉          | 22355968/26421880 [00:19<00:02, 1355869.52it/s]\n",
      "\n",
      " 85%|███████████████████████████████████████████████████████▎         | 22495232/26421880 [00:19<00:02, 1342552.73it/s]\n",
      "\n",
      " 86%|███████████████████████████████████████████████████████▋         | 22634496/26421880 [00:20<00:02, 1343684.27it/s]\n",
      "\n",
      " 86%|████████████████████████████████████████████████████████         | 22773760/26421880 [00:20<00:02, 1333153.57it/s]\n",
      "\n",
      " 87%|████████████████████████████████████████████████████████▎        | 22913024/26421880 [00:20<00:02, 1294244.11it/s]\n",
      "\n",
      " 87%|████████████████████████████████████████████████████████▋        | 23052288/26421880 [00:20<00:02, 1318469.85it/s]\n",
      "\n",
      " 88%|█████████████████████████████████████████████████████████        | 23191552/26421880 [00:20<00:02, 1275294.53it/s]\n",
      "\n",
      " 88%|█████████████████████████████████████████████████████████▍       | 23330816/26421880 [00:20<00:02, 1286735.52it/s]\n",
      "\n",
      " 89%|█████████████████████████████████████████████████████████▊       | 23494656/26421880 [00:20<00:02, 1365317.18it/s]\n",
      "\n",
      " 89%|██████████████████████████████████████████████████████████▏      | 23633920/26421880 [00:20<00:02, 1332778.17it/s]\n",
      "\n",
      " 90%|██████████████████████████████████████████████████████████▌      | 23781376/26421880 [00:20<00:01, 1353460.88it/s]\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████▊      | 23920640/26421880 [00:21<00:01, 1327379.49it/s]\n",
      "\n",
      " 91%|███████████████████████████████████████████████████████████▏     | 24059904/26421880 [00:21<00:01, 1322956.22it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████▌     | 24199168/26421880 [00:21<00:01, 1338887.36it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████▉     | 24354816/26421880 [00:21<00:01, 1332158.35it/s]\n",
      "\n",
      " 93%|████████████████████████████████████████████████████████████▎    | 24494080/26421880 [00:21<00:01, 1304177.40it/s]\n",
      "\n",
      " 93%|████████████████████████████████████████████████████████████▌    | 24633344/26421880 [00:21<00:01, 1320881.08it/s]\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████▉    | 24772608/26421880 [00:21<00:01, 1285831.37it/s]\n",
      "\n",
      " 94%|█████████████████████████████████████████████████████████████▎   | 24903680/26421880 [00:21<00:01, 1291051.99it/s]\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████▌   | 25034752/26421880 [00:21<00:01, 1230817.92it/s]\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████▉   | 25165824/26421880 [00:22<00:01, 1202580.86it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████▎  | 25313280/26421880 [00:22<00:00, 1236014.45it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████▋  | 25460736/26421880 [00:22<00:00, 1297560.73it/s]\n",
      "\n",
      " 97%|██████████████████████████████████████████████████████████████▉  | 25600000/26421880 [00:22<00:00, 1314823.60it/s]\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████▍ | 25763840/26421880 [00:22<00:00, 1394705.15it/s]\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████▊ | 25919488/26421880 [00:22<00:00, 1424954.66it/s]\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████▏| 26066944/26421880 [00:22<00:00, 1300669.90it/s]\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████▍| 26206208/26421880 [00:22<00:00, 1317106.66it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████▊| 26345472/26421880 [00:22<00:00, 1205321.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                        | 0/29515 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "32768it [00:00, 37317.83it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                      | 0/4422102 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|▎                                                                      | 16384/4422102 [00:00<00:55, 79708.12it/s]\n",
      "\n",
      "\n",
      "  1%|▊                                                                      | 49152/4422102 [00:00<00:44, 97829.93it/s]\n",
      "\n",
      "\n",
      "  2%|█▋                                                                   | 106496/4422102 [00:00<00:34, 125857.54it/s]\n",
      "\n",
      "\n",
      "  5%|███▎                                                                 | 212992/4422102 [00:01<00:24, 170370.06it/s]\n",
      "\n",
      "\n",
      "  6%|████▏                                                                | 270336/4422102 [00:01<00:19, 213320.52it/s]\n",
      "\n",
      "\n",
      "  8%|█████▊                                                               | 368640/4422102 [00:01<00:14, 277377.10it/s]\n",
      "\n",
      "\n",
      " 10%|██████▊                                                              | 434176/4422102 [00:01<00:12, 331149.22it/s]\n",
      "\n",
      "\n",
      " 12%|████████▍                                                            | 540672/4422102 [00:01<00:09, 415919.31it/s]\n",
      "\n",
      "\n",
      " 15%|██████████                                                           | 647168/4422102 [00:01<00:07, 508575.42it/s]\n",
      "\n",
      "\n",
      " 17%|███████████▊                                                         | 753664/4422102 [00:01<00:06, 599774.70it/s]\n",
      "\n",
      "\n",
      " 19%|█████████████▍                                                       | 860160/4422102 [00:01<00:05, 689845.84it/s]\n",
      "\n",
      "\n",
      " 22%|██████████████▉                                                      | 958464/4422102 [00:01<00:04, 716018.14it/s]\n",
      "\n",
      "\n",
      " 24%|████████████████▎                                                   | 1056768/4422102 [00:01<00:04, 774348.08it/s]\n",
      "\n",
      "\n",
      " 26%|██████████████████                                                  | 1171456/4422102 [00:02<00:03, 856988.53it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████▊                                                | 1286144/4422102 [00:02<00:03, 924223.53it/s]\n",
      "\n",
      "\n",
      " 32%|█████████████████████▌                                              | 1400832/4422102 [00:02<00:03, 929852.31it/s]\n",
      "\n",
      "\n",
      " 35%|███████████████████████▌                                            | 1531904/4422102 [00:02<00:02, 998047.84it/s]\n",
      "\n",
      "\n",
      " 37%|█████████████████████████▏                                          | 1638400/4422102 [00:02<00:02, 975684.58it/s]\n",
      "\n",
      "\n",
      " 40%|██████████████████████████▌                                        | 1753088/4422102 [00:02<00:02, 1013270.60it/s]\n",
      "\n",
      "\n",
      " 42%|████████████████████████████▏                                      | 1859584/4422102 [00:02<00:02, 1013736.66it/s]\n",
      "\n",
      "\n",
      " 44%|█████████████████████████████▊                                     | 1966080/4422102 [00:02<00:02, 1025942.46it/s]\n",
      "\n",
      "\n",
      " 47%|███████████████████████████████▍                                   | 2072576/4422102 [00:02<00:02, 1018357.59it/s]\n",
      "\n",
      "\n",
      " 49%|█████████████████████████████████▌                                  | 2179072/4422102 [00:03<00:02, 791693.77it/s]\n",
      "\n",
      "\n",
      " 51%|██████████████████████████████████▉                                 | 2269184/4422102 [00:03<00:03, 666658.15it/s]\n",
      "\n",
      "\n",
      " 54%|████████████████████████████████████▌                               | 2375680/4422102 [00:03<00:02, 744801.72it/s]\n",
      "\n",
      "\n",
      " 56%|█████████████████████████████████████▉                              | 2465792/4422102 [00:03<00:02, 766049.17it/s]\n",
      "\n",
      "\n",
      " 58%|███████████████████████████████████████▍                            | 2564096/4422102 [00:03<00:02, 806674.12it/s]\n",
      "\n",
      "\n",
      " 60%|█████████████████████████████████████████                           | 2670592/4422102 [00:03<00:02, 834323.57it/s]\n",
      "\n",
      "\n",
      " 62%|██████████████████████████████████████████▍                         | 2760704/4422102 [00:03<00:02, 694070.01it/s]\n",
      "\n",
      "\n",
      " 64%|███████████████████████████████████████████▋                        | 2842624/4422102 [00:04<00:02, 658609.14it/s]\n",
      "\n",
      "\n",
      " 66%|█████████████████████████████████████████████                       | 2932736/4422102 [00:04<00:02, 702129.62it/s]\n",
      "\n",
      "\n",
      " 68%|██████████████████████████████████████████████▎                     | 3014656/4422102 [00:04<00:02, 699763.18it/s]\n",
      "\n",
      "\n",
      " 71%|███████████████████████████████████████████████▉                    | 3121152/4422102 [00:04<00:01, 768172.61it/s]\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████████████████████████▍                  | 3211264/4422102 [00:04<00:01, 753470.50it/s]\n",
      "\n",
      "\n",
      " 74%|██████████████████████████████████████████████████▋                 | 3293184/4422102 [00:04<00:01, 724575.80it/s]\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████████████████████████▏               | 3391488/4422102 [00:04<00:01, 782720.89it/s]\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████████████████████████▍              | 3473408/4422102 [00:04<00:01, 673270.70it/s]\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████▉             | 3571712/4422102 [00:05<00:01, 720382.15it/s]\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████████████████████████████▍           | 3670016/4422102 [00:05<00:00, 779226.83it/s]\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████▊          | 3760128/4422102 [00:05<00:00, 718540.45it/s]\n",
      "\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████▎        | 3858432/4422102 [00:05<00:00, 770525.02it/s]\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████▌       | 3940352/4422102 [00:05<00:00, 638348.09it/s]\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████████████████████████████▌     | 4071424/4422102 [00:05<00:00, 730641.11it/s]\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████▉    | 4161536/4422102 [00:05<00:00, 625707.18it/s]\n",
      "\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████▍| 4382720/4422102 [00:06<00:00, 780893.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "8192it [00:00, 10832.81it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=tranforms.Compose([\n",
    "        tranforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    ,batch_size=64\n",
    "    ,shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=False\n",
    "    ,download=True\n",
    "    ,transform=tranforms.Compose([\n",
    "        tranforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set\n",
    "    ,batch_size=64\n",
    "    ,shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwkseRrILmFp"
   },
   "source": [
    "## Training with a Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyu42rwaJDdY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1: 2.3202121257781982\n",
      "loss 2: 2.278287887573242\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "batch = next(iter(train_loader)) # Get Batch\n",
    "images, labels = batch \n",
    "\n",
    "preds = network(images) # Pass Batch\n",
    "loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "loss.backward() # Calculate Gradients\n",
    "optimizer.step() # Update Weights\n",
    "\n",
    "\n",
    "print('loss 1:', loss.item())\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "print('loss 2:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYgRBULjLHII"
   },
   "source": [
    "## Training with multitle ephochs : The Complet etraining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yz9JX8tuFIp_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "26427392it [00:40, 1205321.48it/s]                                                                                     \n",
      "\n",
      "\n",
      "4423680it [00:25, 780893.44it/s]                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47318 loss: 522.4115934371948 Loss %  0.7886333333333333\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\n",
    "        \"epoch\", epoch, \n",
    "        \"total_correct:\", total_correct, \n",
    "        \"loss:\", total_loss,\n",
    "        \"Loss % \", (total_correct / len(train_set))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxqWEVaGFOyf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct / len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EmUEP0UOwOf"
   },
   "source": [
    "## Udaicity - Solution2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gL4y-K-kfDRg"
   },
   "outputs": [],
   "source": [
    "# transform = tranforms.Compose([tranforms.ToTensor(), tranforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "# transform = tranforms.Compose([tranforms.ToTensor()])\n",
    "\n",
    "# train_set = torchvision.datasets.FashionMNIST(\n",
    "#     root='./data'\n",
    "#     ,train=True\n",
    "#     ,download=True\n",
    "#     ,transform=transform\n",
    "# )\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_set\n",
    "#     ,batch_size=64\n",
    "#     ,shuffle=True\n",
    "# )\n",
    "\n",
    "# test_set = torchvision.datasets.FashionMNIST(\n",
    "#     root='./data'\n",
    "#     ,train=False\n",
    "#     ,download=True\n",
    "#     ,transform=transform\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_set\n",
    "#     ,batch_size=64\n",
    "#     ,shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOSa8m0wO0KC"
   },
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(784, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128,  64)\n",
    "#         self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "#         # Dropout moduel with 0.2 drop probability\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # make sure input tensor is flattented\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "\n",
    "#         # Now with dropout\n",
    "#         x = self.dropout(F.relu(self.fc1(x)))\n",
    "#         x = self.dropout(F.relu(self.fc2(x)))\n",
    "#         x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "#         # Output so no dropout here\n",
    "#         x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "#         return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRrB5ImCQQDJ"
   },
   "outputs": [],
   "source": [
    "# model = Classifier()\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "IkL_q-UTQf5g",
    "outputId": "f165a2e1-42eb-458b-f8c5-b564f619f310"
   },
   "outputs": [],
   "source": [
    "\n",
    "# epochs = 30\n",
    "# steps = 0\n",
    "# train_losses, test_losses = [], []\n",
    "# for e in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for images, labels in train_loader:\n",
    "#         logps = model(images)\n",
    "#         loss = criterion(logps, labels)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#     else:\n",
    "        \n",
    "#         test_loss = 0\n",
    "#         accuracy = 0\n",
    "#         # Trun off gradionts for validation, saves memeory and computations\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for images, labels in test_loader:\n",
    "#                 log_ps = model(images)\n",
    "#                 test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "#                 ps =  torch.exp(log_ps)\n",
    "#                 top_p, top_class = ps.topk(1, dim=1)\n",
    "#                 equals = top_class == labels.view(*top_class.shape)\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "#         model.train()\n",
    "#         train_losses.append(running_loss/len(train_loader))\n",
    "#         test_losses.append(test_loss/len(test_loader))\n",
    "        \n",
    "#         print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "#               \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "#               \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "#               \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader))\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "XkBp6Gc_XDDM",
    "outputId": "e93c5d9e-d3c8-4c30-edaf-5ff77982e5fc"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(train_losses, label='Training loss')\n",
    "# plt.plot(test_losses, label='validation loss')\n",
    "# plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
