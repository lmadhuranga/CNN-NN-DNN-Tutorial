{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcCuQg_sLtSf"
   },
   "source": [
    "# CNN Training with Fashion Data set - Pytorch A - Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5hx5mp8WFcVn",
    "outputId": "c2d4849b-dd27-4840-ddb6-2b21f95f8f3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1be5b77e608>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tranforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)  # Displa optin for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nk-eQZlLHbDb",
    "outputId": "46b79b48-9d53-4b70-bf86-194a37efb48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KJPGY6-HbAH"
   },
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0VgoSijMHTf"
   },
   "source": [
    "## Load data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9XoXxunMGrV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████▊| 26320896/26421880 [00:22<00:00, 1257752.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/29515 [00:00<?, ?it/s]\n",
      "32768it [00:00, 52215.99it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/4422102 [00:00<?, ?it/s]\n",
      "  0%|▎                                                                      | 16384/4422102 [00:00<00:56, 78208.96it/s]\n",
      "  1%|▊                                                                      | 49152/4422102 [00:00<00:46, 93736.53it/s]\n",
      "  2%|█▋                                                                   | 106496/4422102 [00:01<00:37, 115967.29it/s]\n",
      "  4%|███                                                                  | 196608/4422102 [00:01<00:28, 149167.39it/s]\n",
      "  6%|████▎                                                                | 278528/4422102 [00:01<00:21, 195625.23it/s]\n",
      "  8%|█████▏                                                               | 335872/4422102 [00:01<00:16, 242900.91it/s]\n",
      "  9%|██████                                                               | 385024/4422102 [00:01<00:14, 286033.32it/s]\n",
      " 11%|███████▌                                                             | 483328/4422102 [00:01<00:11, 353395.03it/s]\n",
      " 12%|████████▌                                                            | 548864/4422102 [00:01<00:09, 392522.71it/s]\n",
      " 14%|█████████▍                                                           | 606208/4422102 [00:02<00:11, 331967.11it/s]\n",
      " 17%|███████████▋                                                         | 745472/4422102 [00:02<00:08, 427970.65it/s]\n",
      " 19%|████████████▊                                                        | 819200/4422102 [00:02<00:07, 452422.56it/s]\n",
      " 20%|█████████████▊                                                       | 884736/4422102 [00:02<00:07, 459042.44it/s]\n",
      " 21%|██████████████▊                                                      | 950272/4422102 [00:02<00:07, 477537.26it/s]\n",
      " 23%|███████████████▋                                                    | 1024000/4422102 [00:02<00:06, 519201.56it/s]\n",
      " 25%|████████████████▊                                                   | 1089536/4422102 [00:02<00:06, 515111.39it/s]\n",
      " 26%|█████████████████▋                                                  | 1146880/4422102 [00:02<00:06, 523946.28it/s]\n",
      " 28%|██████████████████▉                                                 | 1228800/4422102 [00:03<00:05, 546650.83it/s]\n",
      " 29%|███████████████████▉                                                | 1294336/4422102 [00:03<00:05, 560121.42it/s]\n",
      " 31%|████████████████████▉                                               | 1359872/4422102 [00:03<00:05, 526251.73it/s]\n",
      " 33%|██████████████████████▎                                             | 1449984/4422102 [00:03<00:05, 566352.91it/s]\n",
      " 35%|███████████████████████▌                                            | 1531904/4422102 [00:03<00:04, 618818.91it/s]\n",
      " 36%|████████████████████████▌                                           | 1597440/4422102 [00:03<00:04, 611984.12it/s]\n",
      " 38%|█████████████████████████▌                                          | 1662976/4422102 [00:03<00:04, 605294.63it/s]\n",
      " 39%|██████████████████████████▋                                         | 1736704/4422102 [00:03<00:04, 612064.82it/s]\n",
      " 41%|███████████████████████████▋                                        | 1802240/4422102 [00:03<00:04, 564382.99it/s]\n",
      " 42%|████████████████████████████▊                                       | 1875968/4422102 [00:04<00:04, 598262.70it/s]\n",
      " 44%|█████████████████████████████▉                                      | 1949696/4422102 [00:04<00:03, 633988.33it/s]\n",
      " 46%|██████████████████████████████▉                                     | 2015232/4422102 [00:04<00:03, 631604.94it/s]\n",
      " 47%|████████████████████████████████▏                                   | 2097152/4422102 [00:04<00:03, 674761.40it/s]\n",
      " 49%|█████████████████████████████████▍                                  | 2170880/4422102 [00:04<00:03, 666138.73it/s]\n",
      " 51%|██████████████████████████████████▌                                 | 2244608/4422102 [00:04<00:03, 643989.29it/s]\n",
      " 53%|███████████████████████████████████▊                                | 2326528/4422102 [00:04<00:03, 686544.30it/s]\n",
      " 54%|████████████████████████████████████▉                               | 2400256/4422102 [00:04<00:03, 604420.64it/s]\n",
      " 57%|██████████████████████████████████████▍                             | 2498560/4422102 [00:05<00:03, 621716.79it/s]\n",
      " 58%|███████████████████████████████████████▌                            | 2572288/4422102 [00:05<00:02, 647527.69it/s]\n",
      " 60%|████████████████████████████████████████▊                           | 2654208/4422102 [00:05<00:02, 690951.96it/s]\n",
      " 62%|█████████████████████████████████████████▉                          | 2727936/4422102 [00:05<00:02, 672367.97it/s]\n",
      " 63%|███████████████████████████████████████████                         | 2801664/4422102 [00:05<00:02, 687994.13it/s]\n",
      " 65%|████████████████████████████████████████████▏                       | 2875392/4422102 [00:05<00:02, 695351.22it/s]\n",
      " 67%|█████████████████████████████████████████████▎                      | 2949120/4422102 [00:05<00:02, 694520.33it/s]\n",
      " 68%|██████████████████████████████████████████████▍                     | 3022848/4422102 [00:05<00:02, 692864.73it/s]\n",
      " 70%|███████████████████████████████████████████████▌                    | 3096576/4422102 [00:05<00:01, 692940.88it/s]\n",
      " 72%|████████████████████████████████████████████████▊                   | 3170304/4422102 [00:05<00:01, 686842.63it/s]\n",
      " 74%|██████████████████████████████████████████████████                  | 3252224/4422102 [00:06<00:01, 685654.46it/s]\n",
      " 76%|███████████████████████████████████████████████████▌                | 3350528/4422102 [00:06<00:01, 715293.25it/s]\n",
      " 77%|████████████████████████████████████████████████████▋               | 3424256/4422102 [00:06<00:01, 721172.36it/s]\n",
      " 79%|█████████████████████████████████████████████████████▊              | 3497984/4422102 [00:06<00:01, 697390.67it/s]\n",
      " 81%|███████████████████████████████████████████████████████             | 3579904/4422102 [00:06<00:01, 666636.79it/s]\n",
      " 83%|████████████████████████████████████████████████████████▌           | 3678208/4422102 [00:06<00:01, 723864.40it/s]\n",
      " 85%|█████████████████████████████████████████████████████████▊          | 3760128/4422102 [00:07<00:01, 474122.28it/s]\n",
      " 87%|██████████████████████████████████████████████████████████▉         | 3833856/4422102 [00:07<00:01, 492377.36it/s]\n",
      " 89%|████████████████████████████████████████████████████████████▋       | 3948544/4422102 [00:07<00:00, 547216.32it/s]\n",
      " 92%|██████████████████████████████████████████████████████████████▍     | 4063232/4422102 [00:07<00:00, 594047.47it/s]\n",
      " 94%|████████████████████████████████████████████████████████████████▏   | 4177920/4422102 [00:07<00:00, 616670.61it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████  | 4292608/4422102 [00:07<00:00, 665691.55it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████▏| 4366336/4422102 [00:07<00:00, 660294.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "8192it [00:00, 16498.71it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:40, 1257752.92it/s]                                                                                     \n",
      "4423680it [00:26, 660294.30it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=tranforms.Compose([\n",
    "        tranforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    ,batch_size=64\n",
    "    ,shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=False\n",
    "    ,download=True\n",
    "    ,transform=tranforms.Compose([\n",
    "        tranforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set\n",
    "    ,batch_size=64\n",
    "    ,shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwkseRrILmFp"
   },
   "source": [
    "## Training with a Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyu42rwaJDdY"
   },
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "batch = next(iter(train_loader)) # Get Batch\n",
    "images, labels = batch \n",
    "\n",
    "preds = network(images) # Pass Batch\n",
    "loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "loss.backward() # Calculate Gradients\n",
    "optimizer.step() # Update Weights\n",
    "\n",
    "\n",
    "print('loss 1:', loss.item())\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "print('loss 2:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYgRBULjLHII"
   },
   "source": [
    "## Training with multitle ephochs : The Complet etraining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yz9JX8tuFIp_"
   },
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\n",
    "        \"epoch\", epoch, \n",
    "        \"total_correct:\", total_correct, \n",
    "        \"loss:\", total_loss,\n",
    "        \"Loss % \", (total_correct / len(train_set))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxqWEVaGFOyf"
   },
   "outputs": [],
   "source": [
    "total_correct / len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EmUEP0UOwOf"
   },
   "source": [
    "## Udaicity - Solution2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gL4y-K-kfDRg"
   },
   "outputs": [],
   "source": [
    "# transform = tranforms.Compose([tranforms.ToTensor(), tranforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "# transform = tranforms.Compose([tranforms.ToTensor()])\n",
    "\n",
    "# train_set = torchvision.datasets.FashionMNIST(\n",
    "#     root='./data'\n",
    "#     ,train=True\n",
    "#     ,download=True\n",
    "#     ,transform=transform\n",
    "# )\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_set\n",
    "#     ,batch_size=64\n",
    "#     ,shuffle=True\n",
    "# )\n",
    "\n",
    "# test_set = torchvision.datasets.FashionMNIST(\n",
    "#     root='./data'\n",
    "#     ,train=False\n",
    "#     ,download=True\n",
    "#     ,transform=transform\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_set\n",
    "#     ,batch_size=64\n",
    "#     ,shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOSa8m0wO0KC"
   },
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(784, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128,  64)\n",
    "#         self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "#         # Dropout moduel with 0.2 drop probability\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # make sure input tensor is flattented\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "\n",
    "#         # Now with dropout\n",
    "#         x = self.dropout(F.relu(self.fc1(x)))\n",
    "#         x = self.dropout(F.relu(self.fc2(x)))\n",
    "#         x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "#         # Output so no dropout here\n",
    "#         x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "#         return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRrB5ImCQQDJ"
   },
   "outputs": [],
   "source": [
    "# model = Classifier()\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "IkL_q-UTQf5g",
    "outputId": "f165a2e1-42eb-458b-f8c5-b564f619f310"
   },
   "outputs": [],
   "source": [
    "\n",
    "# epochs = 30\n",
    "# steps = 0\n",
    "# train_losses, test_losses = [], []\n",
    "# for e in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for images, labels in train_loader:\n",
    "#         logps = model(images)\n",
    "#         loss = criterion(logps, labels)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#     else:\n",
    "        \n",
    "#         test_loss = 0\n",
    "#         accuracy = 0\n",
    "#         # Trun off gradionts for validation, saves memeory and computations\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for images, labels in test_loader:\n",
    "#                 log_ps = model(images)\n",
    "#                 test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "#                 ps =  torch.exp(log_ps)\n",
    "#                 top_p, top_class = ps.topk(1, dim=1)\n",
    "#                 equals = top_class == labels.view(*top_class.shape)\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "#         model.train()\n",
    "#         train_losses.append(running_loss/len(train_loader))\n",
    "#         test_losses.append(test_loss/len(test_loader))\n",
    "        \n",
    "#         print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "#               \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "#               \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "#               \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader))\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "XkBp6Gc_XDDM",
    "outputId": "e93c5d9e-d3c8-4c30-edaf-5ff77982e5fc"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(train_losses, label='Training loss')\n",
    "# plt.plot(test_losses, label='validation loss')\n",
    "# plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
