{"cells":[{"metadata":{"id":"QcCuQg_sLtSf","colab_type":"text"},"cell_type":"markdown","source":"# Dog Cat Classifier - Pretrained - pytroch"},{"metadata":{},"cell_type":"markdown","source":"## if using google colab"},{"metadata":{},"cell_type":"markdown","source":"### Connect Colab to Google drive "},{"metadata":{"id":"sTRTGbS1uYDL","colab_type":"code","outputId":"7780c392-e4d5-4c1e-8b9a-2c810581be4a","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"# from google.colab import drive\n# drive.mount._DEBUG = True\n# # drive.mount('/content/drive', force_remount=True)\n# drive.mount('/content/drive')\n\n# #Change the Directry to your project in GOogle driver (Create a folder named : \"App\")\n# %cd \"/content/drive/My Drive/Colab Notebooks\"\n\n# # List driver\n# !ls\n","execution_count":51,"outputs":[]},{"metadata":{"id":"q53Y_NDnOfvy","colab_type":"text"},"cell_type":"markdown","source":"### Download data set from kaggle\n[Downloading Kaggle Datasets into Google Colab](https://medium.com/@opalkabert/downloading-kaggle-datasets-into-google-colab-fb9654c94235)"},{"metadata":{"id":"oWm-Tfe1KyF8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\n\n# !pip install -U -q kaggle\n# !mkdir -p ~/.kaggle\n\n# from google.colab import files\n# # files.upload()\n\n# !cp kaggle.json ~/.kaggle/\n# # !kaggle datasets list\n\n# !kaggle datasets download -d chetankv/dogs-cats-images\n# !ls","execution_count":52,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check GPU availability"},{"metadata":{"id":"4DR_pw3duWad","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7fc33d41-7eda-471d-d129-329b0b78c2e3","trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\n\n# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":53,"outputs":[{"output_type":"stream","text":"CUDA is available!  Training on GPU ...\n","name":"stdout"}]},{"metadata":{"id":"5hx5mp8WFcVn","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import torch\nimport os\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nfrom torchvision import datasets, transforms, models\n\ntorch.set_printoptions(linewidth=120)  # Displa optin for output\ntorch.set_grad_enabled(True) # Already on by default\n\nbatch_size = 32","execution_count":54,"outputs":[]},{"metadata":{"id":"nk-eQZlLHbDb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"93625a53-b18b-498b-d2a7-e3b21bf591b4","trusted":true},"cell_type":"code","source":"print(torch.__version__)\nprint(torchvision.__version__)","execution_count":55,"outputs":[{"output_type":"stream","text":"1.1.0\n0.3.0\n","name":"stdout"}]},{"metadata":{"id":"6KJPGY6-HbAH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_num_correct(preds, labels):\n    return preds.argmax(dim=1).eq(labels).sum().item()","execution_count":56,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocess images"},{"metadata":{"id":"gL4y-K-kfDRg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\ndata_dir = '../input/dog vs cat/dataset'\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.Resize(size=(224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n# test_transform = transforms.Compose([\n#                                 transforms.Resize(254),\n#                                 transforms.CenterCrop(254),\n#                                 transforms.ToTensor()])\n\n\ntrain_data =  torchvision.datasets.ImageFolder(data_dir + '/training_set', transform = transform)\ntest_data =  torchvision.datasets.ImageFolder(data_dir + '/test_set', transform = transform)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_iterator = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\nvalid_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n# test_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')","execution_count":61,"outputs":[]},{"metadata":{"id":"WcT6RtZCyZfL","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import torchvision.models as models\n\nmodel = models.resnet18(pretrained=True).to(device)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":63,"outputs":[{"output_type":"stream","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Linear(in_features=512, out_features=2).to(device)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()","execution_count":67,"outputs":[]},{"metadata":{"id":"qRrB5ImCQQDJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())","execution_count":68,"outputs":[]},{"metadata":{"id":"IkL_q-UTQf5g","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def calculate_accuracy(fx, y):\n    preds = fx.max(1, keepdim=True)[1]\n    correct = preds.eq(y.view_as(preds)).sum()\n    acc = correct.float()/preds.shape[0]\n    return acc","execution_count":69,"outputs":[]},{"metadata":{"id":"XkBp6Gc_XDDM","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def train(model, device, iterator, optimizer, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for (x, y) in iterator:\n        \n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n                \n        fx = model(x)\n        \n        loss = criterion(fx, y)\n        \n        acc = calculate_accuracy(fx, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, device, iterator, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for (x, y) in iterator:\n\n            x = x.to(device)\n            y = y.to(device)\n\n            fx = model(x)\n\n            loss = criterion(fx, y)\n\n            acc = calculate_accuracy(fx, y)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nSAVE_DIR = 'models'\nMODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'resnet18-dogs-vs-cats.pt')\n\nbest_valid_loss = float('inf')\n\nif not os.path.isdir(f'{SAVE_DIR}'):\n    os.makedirs(f'{SAVE_DIR}')\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n    valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n    \n    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% |')","execution_count":72,"outputs":[{"output_type":"stream","text":"| Epoch: 01 | Train Loss: 0.206 | Train Acc: 92.21% | Val. Loss: 0.110 | Val. Acc: 96.09% |\n| Epoch: 02 | Train Loss: 0.113 | Train Acc: 95.65% | Val. Loss: 0.084 | Val. Acc: 96.92% |\n| Epoch: 03 | Train Loss: 0.094 | Train Acc: 96.31% | Val. Loss: 0.089 | Val. Acc: 96.68% |\n| Epoch: 04 | Train Loss: 0.091 | Train Acc: 96.35% | Val. Loss: 0.082 | Val. Acc: 96.83% |\n| Epoch: 05 | Train Loss: 0.087 | Train Acc: 96.71% | Val. Loss: 0.084 | Val. Acc: 96.73% |\n| Epoch: 06 | Train Loss: 0.082 | Train Acc: 96.85% | Val. Loss: 0.075 | Val. Acc: 97.41% |\n| Epoch: 07 | Train Loss: 0.075 | Train Acc: 97.05% | Val. Loss: 0.073 | Val. Acc: 97.12% |\n| Epoch: 08 | Train Loss: 0.077 | Train Acc: 96.96% | Val. Loss: 0.076 | Val. Acc: 97.02% |\n| Epoch: 09 | Train Loss: 0.078 | Train Acc: 96.71% | Val. Loss: 0.062 | Val. Acc: 97.41% |\n| Epoch: 10 | Train Loss: 0.074 | Train Acc: 97.19% | Val. Loss: 0.058 | Val. Acc: 98.10% |\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n\ntest_loss, test_acc = evaluate(model, device, valid_iterator, criterion)\n\nprint(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:05.2f}% |')","execution_count":73,"outputs":[{"output_type":"stream","text":"| Test Loss: 0.062 | Test Acc: 97.75% |\n","name":"stdout"}]}],"metadata":{"colab":{"name":"2.cnn - pytroch - Dog Cat Classifier.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}